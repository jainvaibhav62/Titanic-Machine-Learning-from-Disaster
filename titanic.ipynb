{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/titanic/train.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n0            1         0       3    male  22.0      1      0   7.2500        S\n1            2         1       1  female  38.0      1      0  71.2833        C\n2            3         1       3  female  26.0      0      0   7.9250        S\n3            4         1       1  female  35.0      1      0  53.1000        S\n4            5         0       3    male  35.0      0      0   8.0500        S","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = pd.DataFrame(data)\n# data\n# data.isna().sum()\n# data[['Cabin']]\n# data = data.dropna(subset=['Embarked'])\n# data = data.drop(['Name','Ticket','Fare'],axis=1)\n# data[['Age']].mean()\n# data[['Age']] = data[['Age']].fillna(data[['Age']].mean())\n# data = data.drop(['Cabin'],axis=1)\n# data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data=data.drop(['Name', 'Ticket','Cabin'],axis=1)\ndata","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"     PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare  \\\n0              1         0       3    male  22.0      1      0   7.2500   \n1              2         1       1  female  38.0      1      0  71.2833   \n2              3         1       3  female  26.0      0      0   7.9250   \n3              4         1       1  female  35.0      1      0  53.1000   \n4              5         0       3    male  35.0      0      0   8.0500   \n..           ...       ...     ...     ...   ...    ...    ...      ...   \n886          887         0       2    male  27.0      0      0  13.0000   \n887          888         1       1  female  19.0      0      0  30.0000   \n888          889         0       3  female   NaN      1      2  23.4500   \n889          890         1       1    male  26.0      0      0  30.0000   \n890          891         0       3    male  32.0      0      0   7.7500   \n\n    Embarked  \n0          S  \n1          C  \n2          S  \n3          S  \n4          S  \n..       ...  \n886        S  \n887        S  \n888        S  \n889        C  \n890        Q  \n\n[891 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna(subset=['Embarked'])\n# data.isna().sum()","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.impute import SimpleImputer\n# imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n# imputer.fit(data.iloc[:,4])\n# data.iloc[:, 4] = imputer.transform(data.iloc[:, 4])\n\ndata['Age'].fillna(data['Age'].mean(), inplace=True)","execution_count":27,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py:4439: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  downcast=downcast,\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"PassengerId    0\nSurvived       0\nPclass         0\nSex            0\nAge            0\nSibSp          0\nParch          0\nFare           0\nEmbarked       0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.iloc[:,:-1]\nY = data.iloc[:,-1]  ","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nY = le.fit_transform(Y)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(x_train, y_train)","execution_count":44,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","name":"stderr"},{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"LogisticRegression(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","execution_count":50,"outputs":[{"output_type":"stream","text":"[[2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [0 0]\n [2 0]\n [2 2]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [0 2]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [2 0]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [2 2]\n [2 0]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [2 2]\n [2 0]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 1]\n [2 0]\n [2 1]\n [2 2]\n [2 2]\n [2 0]\n [2 0]\n [2 2]\n [2 2]\n [2 0]\n [2 2]\n [2 0]\n [2 2]\n [2 2]\n [2 1]\n [2 1]\n [2 2]\n [2 2]\n [2 1]\n [0 2]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 1]\n [2 0]\n [2 2]\n [2 0]\n [2 2]\n [2 1]\n [2 0]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [0 0]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [2 0]\n [2 2]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [2 0]\n [2 0]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [0 0]\n [2 0]\n [2 2]\n [2 2]\n [2 2]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [0 2]\n [2 2]\n [2 0]\n [2 1]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 2]\n [2 0]\n [2 2]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":52,"outputs":[{"output_type":"stream","text":"[[  3   0  27]\n [  0   0  16]\n [  3   0 129]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"0.7415730337078652"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(x_train, y_train)","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"KNeighborsClassifier()"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":55,"outputs":[{"output_type":"stream","text":"[[  6   1  23]\n [  0   2  14]\n [ 19   5 108]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"0.651685393258427"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(x_train, y_train)","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"SVC(kernel='linear', random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":61,"outputs":[{"output_type":"stream","text":"[[  1   0  29]\n [  0   0  16]\n [  1   0 131]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"0.7415730337078652"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(x_train, y_train)","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"SVC(random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":64,"outputs":[{"output_type":"stream","text":"[[  0   0  30]\n [  0   0  16]\n [  0   0 132]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":64,"data":{"text/plain":"0.7415730337078652"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)","execution_count":66,"outputs":[{"output_type":"execute_result","execution_count":66,"data":{"text/plain":"GaussianNB()"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":68,"outputs":[{"output_type":"stream","text":"[[ 11   4  15]\n [  0   9   7]\n [ 15  15 102]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":68,"data":{"text/plain":"0.6853932584269663"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"DecisionTreeClassifier(criterion='entropy', random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":71,"outputs":[{"output_type":"stream","text":"[[ 23   0   7]\n [  0  11   5]\n [ 17   6 109]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"0.8033707865168539"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)","execution_count":84,"outputs":[{"output_type":"execute_result","execution_count":84,"data":{"text/plain":"RandomForestClassifier(criterion='entropy', n_estimators=200, random_state=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":85,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":86,"outputs":[{"output_type":"stream","text":"[[ 16   0  14]\n [  0   7   9]\n [  9   1 122]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":86,"data":{"text/plain":"0.8146067415730337"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}